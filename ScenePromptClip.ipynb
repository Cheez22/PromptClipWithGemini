{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook walk your through the process of creating clips with LLM prompts. \n",
    "\n",
    "Pick a video, decide your prompt, generate a new clip ⚡️\n",
    "\n",
    "It's as simple as it sounds.\n",
    "\n",
    "If you want to go extra mile you can add Image Overlays or Audio overlays on these clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types==0.6.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: anthropic==0.15.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.15.0)\n",
      "Requirement already satisfied: anyio==4.2.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (4.2.0)\n",
      "Requirement already satisfied: backoff==2.2.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: certifi==2024.2.2 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: distro==1.9.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: exceptiongroup==1.2.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: filelock==3.13.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (3.13.1)\n",
      "Requirement already satisfied: fsspec==2024.2.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2024.2.0)\n",
      "Requirement already satisfied: google-generativeai==0.5.4 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.5.4)\n",
      "Requirement already satisfied: h11==0.14.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.14.0)\n",
      "Requirement already satisfied: httpcore==1.0.2 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (1.0.2)\n",
      "Requirement already satisfied: httpx==0.26.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub==0.20.3 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (0.20.3)\n",
      "Requirement already satisfied: idna==3.6 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (3.6)\n",
      "Requirement already satisfied: packaging==23.2 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (23.2)\n",
      "Requirement already satisfied: pydantic==2.6.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (2.6.1)\n",
      "Requirement already satisfied: pydantic_core==2.16.2 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (2.16.2)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (1.0.1)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (6.0.1)\n",
      "Requirement already satisfied: requests==2.31.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (2.31.0)\n",
      "Requirement already satisfied: sniffio==1.3.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers==0.15.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (0.15.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (4.66.1)\n",
      "Requirement already satisfied: typing_extensions==4.9.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (4.9.0)\n",
      "Requirement already satisfied: urllib3==2.2.0 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (2.2.0)\n",
      "Requirement already satisfied: videodb==0.2.3 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (0.2.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in ./venv/lib/python3.12/site-packages (from google-generativeai==0.5.4->-r requirements.txt (line 11)) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in ./venv/lib/python3.12/site-packages (from google-generativeai==0.5.4->-r requirements.txt (line 11)) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in ./venv/lib/python3.12/site-packages (from google-generativeai==0.5.4->-r requirements.txt (line 11)) (2.136.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./venv/lib/python3.12/site-packages (from google-generativeai==0.5.4->-r requirements.txt (line 11)) (2.31.0)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.12/site-packages (from google-generativeai==0.5.4->-r requirements.txt (line 11)) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai==0.5.4->-r requirements.txt (line 11)) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./venv/lib/python3.12/site-packages (from google-api-core->google-generativeai==0.5.4->-r requirements.txt (line 11)) (1.63.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 11)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 11)) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in ./venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 11)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 11)) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai==0.5.4->-r requirements.txt (line 11)) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai==0.5.4->-r requirements.txt (line 11)) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./venv/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 11)) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 11)) (0.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# But first, let's install the dependecies.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do all the required imports\n",
    "import videodb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from videodb import SearchType, MediaType, play_stream\n",
    "from videodb.timeline import Timeline, VideoAsset, TextAsset, ImageAsset, AudioAsset\n",
    "from videodb.asset import TextStyle\n",
    "\n",
    "from video_prompter import scene_prompter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the video\n",
    "\n",
    "You can either use a fresh video from Youtube etc. or choose an exisitng one already uploaded on your VideoDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id: m-59f3bc33-8895-4116-98bc-33af6a8ad2cf, name: Mr. Bean | Episode 1 | Mr. Bean Official\n"
     ]
    }
   ],
   "source": [
    "# TODO: setup .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to VideoDB\n",
    "conn = videodb.connect()\n",
    "coll = conn.get_collection()\n",
    "\n",
    "# TODO: Add video_id if video already exists in the collection\n",
    "video_id = \"\"\n",
    "video_url = \"https://www.youtube.com/watch?v=7Im2I6STbms\"\n",
    "\n",
    "if not video_id:\n",
    "    video = coll.upload(url=video_url)\n",
    "else:\n",
    "    video = coll.get_video(video_id)\n",
    "\n",
    "print(f\"video_id: {video.id}, name: {video.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Scenes\n",
    "\n",
    "Here you can either add the scene_index_id of the video if available or you can leave it blank to index the video for visual retreival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video is indexed with scene_index_id ccbcd0a4a4a58a1f with 137 scenes.\n"
     ]
    }
   ],
   "source": [
    "# Add scene_index_id here if already indexed.\n",
    "scene_index_id = \"\"\n",
    "\n",
    "if not scene_index_id:\n",
    "    scene_index_id = video.index_scenes(\n",
    "        extraction_config={\n",
    "            \"threshold\": 20, \n",
    "            \"frame_count\": 3\n",
    "        },\n",
    "        prompt=\"Summarize the essence of the scene in one or two concise sentences without focusing on individual images.\"\n",
    "    )\n",
    "scenes = video.get_scene_index(scene_index_id)\n",
    "print(f\"video is indexed with scene_index_id {scene_index_id} with {len(scenes)} scenes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your Prompt\n",
    "To create a clip using the `scene_prompter` function from a video, it's crucial to craft a specific prompt that will help identify the most relevant segments for your use case. This prompt should highlight the themes, topics, or specific phrases you're interested in. The function then analyzes the video's visual content to find segments that match your criteria.\n",
    "\n",
    "Before you can use `scene_prompter`, make sure the video's scenes are indexed with the video.index_scenes() function. This prepares the video for analysis by making its visual content searchable.\n",
    "\n",
    "The `scene_prompter` will return sentences or segments from the video that match your prompt. Review these to ensure they align with your needs. You can then use these segments to create your clip, focusing on the content that's most relevant to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"find the moment where mr.bean is attempting to cheat by peeking over at the answer sheet of man beside him, just find this singular moment with high accuracy.\"\n",
    "result = scene_prompter(scenes, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Clip\n",
    "To generate a clip, we'll use VideoDB's `keyword search` feature. We already leveraged the power of the LLM (Large Language Model) to identify relevant sentences. We'll use the search results to create a programmable video stream. Here's how you can approach this process:\n",
    "\n",
    "We have the keywords in the `results` variable. Input these keywords into VideoDB's keyword search feature. This function will search through the indexed scenes of your videos to find matches.\n",
    "\n",
    "The search will return a SearchResult object, which contains detailed information about the found segments, including their timestamps, the text of the scene description, and possibly other metadata.\n",
    "\n",
    "**Create a Programmable Video Stream with Timeline**: With the specific segments identified, you can now use the Timeline to create a new programmable video stream. The Timeline tool allows you to stitch together video segments based on the timestamps provided in the SearchResult object. You can arrange, cut, or combine these segments to craft a fresh video stream that focuses on your topic of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_timestamps(result, sort=\"time\"):\n",
    "    result_timestamps = []\n",
    "\n",
    "    for description in result:\n",
    "        # keyword search on each result description\n",
    "        search_res = video.search(description, index_type=SearchType.scene, search_type=SearchType.keyword, scene_index_id=scene_index_id)\n",
    "        matched_segments = search_res.get_shots()\n",
    "        \n",
    "        # no exact match found.\n",
    "        if len(matched_segments) == 0:\n",
    "            continue\n",
    "\n",
    "        # videoashot of matched segment \n",
    "        video_shot = matched_segments[0]\n",
    "\n",
    "        # storing the timestamps and description\n",
    "        result_timestamps.append((video_shot.start, video_shot.end, video_shot.text))\n",
    "\n",
    "    # sorting the result by time\n",
    "    if sort and sort == \"time\":\n",
    "        result_timestamps = sorted(set(result_timestamps), key=lambda x:x[0])\n",
    "    return result_timestamps\n",
    "\n",
    "# Creating and returning timeline of given result timestamps\n",
    "def get_clip_timeline(result_timestamps, top_n=None, debug=False):\n",
    "    timeline = Timeline(conn)\n",
    "    duration = 0\n",
    "    if top_n:\n",
    "        existing_count = len(result_timestamps)\n",
    "        result_timestamps = result_timestamps[:top_n]\n",
    "        if debug:\n",
    "            print(f\"Picked top {top_n} from {existing_count}\")\n",
    "    for result_timestamp in result_timestamps:\n",
    "        start = float(result_timestamp[0])\n",
    "        end = float(result_timestamp[1])\n",
    "        description = result_timestamp[2]\n",
    "        if debug:\n",
    "            print(start, end, description)\n",
    "        duration += (end-start)\n",
    "        timeline.add_inline(VideoAsset(asset_id=video.id, start=start, end=end))\n",
    "    return timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple stream of result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_timestamps = get_result_timestamps(result)\n",
    "timeline = get_clip_timeline(result_timestamps, top_n=1) # get timeline of 1st result\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stream with text overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = get_clip_timeline(result_timestamps, top_n=1)\n",
    "left = TextAsset(\n",
    "    text=\"XXXX\",\n",
    "    duration=duration,\n",
    "    style=TextStyle(\n",
    "        x=180,\n",
    "        y=15,\n",
    "        font = \"Inter\",\n",
    "        fontsize = 25,\n",
    "        fontcolor = \"#002869\",\n",
    "    )\n",
    ")\n",
    "right = TextAsset(\n",
    "    text=\"YYYY\",\n",
    "    duration=duration,\n",
    "    style=TextStyle(\n",
    "        x=390,\n",
    "        y=15,\n",
    "        font = \"Inter\",\n",
    "        fontsize = 25, \n",
    "        fontcolor = \"#00692c\",\n",
    "    )\n",
    ")\n",
    "timeline.add_overlay(0, left)\n",
    "timeline.add_overlay(0, right)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream with Image overlay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = get_clip_timeline(result_timestamps, top_n=1)\n",
    "\n",
    "image1_id = \"\"\n",
    "if not image1_id:\n",
    "    image1_url = \"https://upload.wikimedia.org/wikipedia/sco/thumb/d/d1/Ferrari-Logo.svg/344px-Ferrari-Logo.svg.png\"\n",
    "    image1 = coll.upload(url=image1_url, media_type=MediaType.image)\n",
    "    image1_id = image1.id\n",
    "    print(f\"image1_id: {image1_id}\")\n",
    "\n",
    "image2_id = \"\" \n",
    "if not image2_id:\n",
    "    image2_url = \"https://upload.wikimedia.org/wikipedia/en/thumb/6/66/McLaren_Racing_logo.svg/512px-McLaren_Racing_logo.svg.png\"\n",
    "    image2 = coll.upload(url=image2_url, media_type=MediaType.image)\n",
    "    image2_id = image2.id\n",
    "    print(f\"image2_id: {image2_id}\")\n",
    "\n",
    "left = ImageAsset(\n",
    "    asset_id=image1_id,\n",
    "    duration=duration,\n",
    "    width=128,\n",
    "    height=40,\n",
    "    x=180,\n",
    "    y=180,\n",
    ")\n",
    "right = ImageAsset(\n",
    "    asset_id=image2_id,\n",
    "    duration=duration,\n",
    "    width=86,\n",
    "    height=140,\n",
    "    x=390,\n",
    "    y=200\n",
    ")\n",
    "timeline.add_overlay(0, left)\n",
    "timeline.add_overlay(0, right)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another prompt with simple compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"find all the car gags with high accuracy\"\n",
    "result = scene_prompter(scenes, user_prompt)\n",
    "result_timestamps = get_result_timestamps(result)\n",
    "timeline = get_clip_timeline(result_timestamps)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
